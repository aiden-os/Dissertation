{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNF0TvObpu7e5L1CqPxSENS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import required libraries"],"metadata":{"id":"K8zKMUklXUct"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_Uis3OQMYM_"},"outputs":[],"source":["!pip install transformers torch accelerate tensorflow-hub bert-tensorflow tensorflow tqdm bert-score"]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"id":"Z_dcJ2QZ4fmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install rouge-score"],"metadata":{"id":"bnRFhAgo4g5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sacrebleu"],"metadata":{"id":"DU0dYrX-4h70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification, MarianMTModel, MarianTokenizer, BertConfig\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification\n","from transformers import LlamaTokenizer, LlamaForCausalLM\n","from transformers import pipeline\n","from sklearn.utils.class_weight import compute_class_weight\n","from torch.utils.data import Dataset\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import resample\n","import pandas as pd\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from datetime import datetime\n","from torch.utils.data import DataLoader\n","import re\n","import nltk\n","from nltk.corpus import wordnet\n","import random\n","from tqdm import tqdm\n","import concurrent.futures\n","from nltk.tokenize import sent_tokenize\n","import matplotlib.pyplot as plt\n","import json\n","import numpy as np\n","from bert_score import score\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"id":"aLK5Q2pH4jD5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing full posts"],"metadata":{"id":"Gh3iqlEyXXmv"}},{"cell_type":"code","source":["nltk.download('punkt')\n","dataset_path = \"/content/drive/My Drive/Diss_Dataset/dataset500_cleaned.csv\"\n","data = pd.read_csv(dataset_path)\n","data[\"userid\"] = data.iloc[:, 0]\n","data[\"posts\"] = data.iloc[:, 1]\n","data[\"label\"] = data.iloc[:, 2]\n","\n","data['posts'] = data['posts'].str.strip('[]').str.split(\"', '\")\n","data['posts'] = data['posts'].apply(lambda x: [post.strip(\"' \") for post in x])\n","\n","def clean_post(post):\n","    post = re.sub(r'\\*+', '', post)\n","    post = re.sub(r'\\s+', ' ', post)\n","    post = re.sub(r'&gt;', '', post)\n","    post = re.sub(r'[^\\x00-\\x7F]+', '', post)\n","    post = re.sub(r'\"[^\"]*\"', '', post)\n","    post = re.sub(r'\\([^)]*\\)', '', post)\n","    post = re.sub(r'[()]', '', post)\n","    post = re.sub(r'\\[[^\\]]*\\]', '', post)\n","    post = re.sub(r'[\\[\\]]', '', post)\n","    return post.strip().lower()\n","\n","data[\"clean_posts\"] = data[\"posts\"].apply(lambda posts: [clean_post(post) for post in posts])\n","data['combined_posts'] = data['clean_posts'].apply(lambda posts: ' '.join(posts))\n","\n","\n","print(data['combined_posts'][1])"],"metadata":{"id":"8yVoMKac4kYJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing top 5 sentences, risk rating and number of supportive sentences"],"metadata":{"id":"sGccLUOMXcqt"}},{"cell_type":"code","source":["top_5_path = \"/content/drive/My Drive/Diss_Dataset/top_sentences_for_all_users.csv\"\n","top_5_df = pd.read_csv(top_5_path)\n","\n","user_risk_supportiveness_path = \"/content/drive/My Drive/Diss_Dataset/user_risk_with_supportiveness.csv\"\n","risk_supportiveness_df = pd.read_csv(user_risk_supportiveness_path)"],"metadata":{"id":"eV84RICR4tKZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating meta-information"],"metadata":{"id":"SFuK29xTXh_J"}},{"cell_type":"code","source":["def create_meta_info(user_id, risk_df, top_5_df):\n","    risk_info = risk_df[risk_df['userid'] == user_id]\n","    top_5_info = top_5_df[top_5_df['userid'] == user_id]\n","\n","    if not risk_info.empty:\n","        risk_val = risk_info['risk_rating'].values[0]\n","        risk = \"Very High\" if risk_val == 5 else \"High\" if risk_val == 4 else \"Medium\" if risk_val == 3 else \"Low\" if risk_val == 2 else \"Very Low\" if risk_val == 1 else \"No\"\n","        supportiveness_ratio = risk_info['supportiveness_ratio'].values[0]\n","    else:\n","        risk = \"Unknown\"\n","        supportiveness_ratio = \"Unknown\"\n","\n","    top_5_sentences = ' '.join(top_5_info['sentence'].tolist())\n","    supportive_percentage = (supportiveness_ratio * 100).round(2)\n","\n","    meta_info = f\"The author indicates {risk} suicidal risk, with {supportive_percentage}% of their sentences supporting other users.\"\n","    return meta_info"],"metadata":{"id":"E2nFt9Dk4uGn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading the chosen Mistral model, and prompting method"],"metadata":{"id":"7U2lgTBqXlPw"}},{"cell_type":"code","source":["model_name = \"/content/drive/My Drive/Diss_Dataset/Mistral7b\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")"],"metadata":{"id":"SvF3KGlF4vLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = \"\"\"\n","[INST]\n","In one paragraph, summarise the provided text from the author on Reddit:\\n\n","#Full input text:\n","{posts}\\n\n","#Meta-Information:\n","{meta_info}\\n\n","Summary: [/INST]\n","\n","\"\"\""],"metadata":{"id":"aBq1DZWS43o7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generating a response from the model"],"metadata":{"id":"YgmoxIanXqwf"}},{"cell_type":"code","source":["def truncate_text(text, max_input_tokens=1800):\n","    tokens = tokenizer.tokenize(text)\n","    if len(tokens) > max_input_tokens:\n","        truncated_tokens = tokens[:max_input_tokens]\n","        truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n","        return truncated_text\n","    return text\n","\n","reserved_tokens = 512\n","\n","def extract_assistant_response(text):\n","    assistant_marker = \"[/INST]\"\n","    if assistant_marker in text:\n","        summary = text.split(assistant_marker)[1].strip()\n","    else:\n","        summary = text.strip()\n","\n","    return summary\n","\n","results = []\n","\n","for user_id in risk_supportiveness_df['userid'].unique():\n","\n","    full_text = data[data['userid'] == user_id]['combined_posts'].values[0]\n","\n","    meta_info = create_meta_info(user_id, risk_supportiveness_df, top_5_df)\n","\n","    truncated_text = truncate_text(full_text, max_input_tokens=2048 - reserved_tokens)\n","\n","    input_text = prompt.format(posts=truncated_text, meta_info=meta_info)\n","    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n","    outputs = model.generate(**inputs, max_new_tokens=200)\n","    summary = extract_assistant_response(tokenizer.decode(outputs[0], skip_special_tokens=True))\n","\n","    results.append({\n","        \"userid\": user_id,\n","        \"summary\": summary,\n","    })\n","\n","results_df = pd.DataFrame(results)\n","results_df.to_csv(\"/content/drive/My Drive/Diss_Dataset/all_summaries.csv\", index=False)"],"metadata":{"id":"3c_M5CRp47Vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_assistant_response(text):\n","    assistant_marker = \"Summary:\"\n","    if assistant_marker in text:\n","        summary = text.split(assistant_marker)[1].strip()\n","    else:\n","        summary = text.strip()\n","\n","    summary = summary.split('\\n')[0].strip()\n","\n","    return summary\n","\n","for row in results:\n","    summary = extract_assistant_response(row['summary'])\n","    row['summary'] = summary\n","\n","results_df = pd.DataFrame(results)\n","print(results_df.head())"],"metadata":{"id":"PNMrTMiR7n1x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_df.to_csv(\"/content/drive/My Drive/Diss_Dataset/summary_by_user_test.csv\", index=False)"],"metadata":{"id":"_O0FbZMS8VLC"},"execution_count":null,"outputs":[]}]}