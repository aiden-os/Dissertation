{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOPlPFVSF3q0r+WYagq8duf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8133a3b35d86489dab76b93d0cf4a982":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4fbdfe5f44384a6eaa15a811f6580386","IPY_MODEL_d4c8e4e2391a4443bd261443303fad5f","IPY_MODEL_15e923cf559c49f59a68645d63211369"],"layout":"IPY_MODEL_df82616e91474e05a2353b02dd7d1c15"}},"4fbdfe5f44384a6eaa15a811f6580386":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0b8b5a3f6a44878c61943a07295225","placeholder":"​","style":"IPY_MODEL_ba297767915949489d5ac7330c5e3269","value":"Loading checkpoint shards: 100%"}},"d4c8e4e2391a4443bd261443303fad5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22b7f697e934c839f40790690038b8d","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8f025f936ed4a42bbf842083cf5b4d8","value":3}},"15e923cf559c49f59a68645d63211369":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dae09f757de040879c3b39475f9d8475","placeholder":"​","style":"IPY_MODEL_0c8348e04bf64231b524fcc12664cf4e","value":" 3/3 [02:17&lt;00:00, 44.01s/it]"}},"df82616e91474e05a2353b02dd7d1c15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef0b8b5a3f6a44878c61943a07295225":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba297767915949489d5ac7330c5e3269":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a22b7f697e934c839f40790690038b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8f025f936ed4a42bbf842083cf5b4d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dae09f757de040879c3b39475f9d8475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c8348e04bf64231b524fcc12664cf4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Importing required libraries"],"metadata":{"id":"P38d0W8yVmUi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ5fZxDwMfuP"},"outputs":[],"source":["!pip install transformers torch accelerate tensorflow-hub bert-tensorflow tensorflow tqdm bert-score"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification, MarianMTModel, MarianTokenizer, BertConfig\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification\n","from transformers import LlamaTokenizer, LlamaForCausalLM\n","from transformers import pipeline\n","from sklearn.utils.class_weight import compute_class_weight\n","from torch.utils.data import Dataset\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import resample\n","import pandas as pd\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from datetime import datetime\n","from torch.utils.data import DataLoader\n","import re\n","import nltk\n","from nltk.corpus import wordnet\n","import random\n","from tqdm import tqdm\n","import concurrent.futures\n","from nltk.tokenize import sent_tokenize\n","import matplotlib.pyplot as plt\n","import json\n","import numpy as np\n","from bert_score import score\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"id":"XDZlz3SoMq6o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing user summaries and risk levels"],"metadata":{"id":"yslurm6WVsRk"}},{"cell_type":"code","source":["summary_path = \"/content/drive/My Drive/Diss_Dataset/summary_by_user.csv\"\n","summary_df = pd.read_csv(summary_path)\n","summary_df.head()\n","\n","user_risk_supportiveness_path = \"/content/drive/My Drive/Diss_Dataset/user_risk_with_supportiveness.csv\"\n","risk_supportiveness_df = pd.read_csv(user_risk_supportiveness_path)"],"metadata":{"id":"2yOLucjxZbme"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Formatting the summary with the risk level and number of supportive sentences"],"metadata":{"id":"3Rzl2v3VV8DW"}},{"cell_type":"code","source":["def create_summary(summary,userid,risk_supportiveness_df):\n","    risk_info = risk_supportiveness_df[risk_supportiveness_df['userid'] == userid]\n","    if not risk_info.empty:\n","        risk_val = risk_info['risk_rating'].values[0]\n","        risk = \"Very High\" if risk_val == 5 else \"High\" if risk_val == 4 else \"Medium\" if risk_val == 3 else \"Low\" if risk_val == 2 else \"Very Low\" if risk_val == 1 else \"No\"\n","        supportiveness_ratio = risk_info['supportiveness_ratio'].values[0]\n","    else:\n","        risk = \"Unknown\"\n","        supportiveness_ratio = \"Unknown\"\n","\n","    supportive_percentage = (supportiveness_ratio * 100).round(2)\n","\n","    full_summary = f\"The author indicates {risk} suicidal risk, with {supportive_percentage}% of their sentences supporting other users. {summary}\"\n","    return full_summary\n"],"metadata":{"id":"mUk56iBo86Uo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Clearing GPU RAM between models"],"metadata":{"id":"RfovPKEBWHwJ"}},{"cell_type":"code","source":["import gc\n","del model1\n","del tokenizer1\n","torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"id":"AzwW4gvHNT77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"-a8MmtF0NliD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialising a model"],"metadata":{"id":"GrNW3w6YWMF_"}},{"cell_type":"code","source":["model_name1 = \"/content/drive/My Drive/Diss_Dataset/DPO7b\"\n","tokenizer1 = AutoTokenizer.from_pretrained(model_name1)\n","model1 = AutoModelForCausalLM.from_pretrained(model_name1, device_map=\"auto\")"],"metadata":{"id":"1wSc6rPoWE1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name1 = \"/content/drive/My Drive/Diss_Dataset/Mistral7b\"\n","tokenizer1 = AutoTokenizer.from_pretrained(model_name1)\n","model1 = AutoModelForCausalLM.from_pretrained(model_name1, torch_dtype=torch.bfloat16, device_map=\"auto\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8133a3b35d86489dab76b93d0cf4a982","4fbdfe5f44384a6eaa15a811f6580386","d4c8e4e2391a4443bd261443303fad5f","15e923cf559c49f59a68645d63211369","df82616e91474e05a2353b02dd7d1c15","ef0b8b5a3f6a44878c61943a07295225","ba297767915949489d5ac7330c5e3269","a22b7f697e934c839f40790690038b8d","a8f025f936ed4a42bbf842083cf5b4d8","dae09f757de040879c3b39475f9d8475","0c8348e04bf64231b524fcc12664cf4e"]},"id":"HsSOCSaSZ5-U","executionInfo":{"status":"ok","timestamp":1725406175535,"user_tz":-60,"elapsed":140178,"user":{"displayName":"Aiden o'sullivan","userId":"05349309044784945157"}},"outputId":"9dd1e7c0-32b1-4735-b134-c01f9c982777"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8133a3b35d86489dab76b93d0cf4a982"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Prompts for Tulu-2-DPO-7b"],"metadata":{"id":"sQj-MjxbWQWq"}},{"cell_type":"code","source":["Zero_prompt_model1 = \"\"\"\n","<|user|> In one paragraph, produce a response to the patient (referred to as the author), based on the provided summary.\\n\n","Assume the patient is based in the UK with the following helplines:\\n\n","Emergency Services: 999.\n","Samaritans helpline: 116 123.\n","SHOUT texting helpline: 85258.\n","\n","Input summary to be used for response: {summary}\\n\n","\n","<|assistant|> Response:\\n\n","\n","\"\"\""],"metadata":{"id":"NcHvOas5Z9OB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CoT_prompt_model1 = \"\"\"\n","<|user|>\n","As a mental health expert, your task is to provide a positive, empathetic and supportative message to the patient (referred to as the author), directly from the provided summary.\n","\n","Consider:\n","**\n","Consider these suggested response stragegies by potiential characteristics of the message, only include the response strategies most related to the patients's needs:\n","Loss of control:  Advising, Interpretation, Offering Group Support, Emotional Support.\n","Acute loneliness: Offering Group Support, Cogitive Change Inducement, Interpretation.\n","Emptiness: Persuasion, Interpretation, Cognitive Change Inducement, Advising.\n","Narcissistic wound: Empowerment, Interpretation, Persuasion, Emotional Support.\n","Irreversibility: Emotional Support, Advising, Persuasion, Offering Group Support.\n","Loss of energy: Empowerment, Emotional Support, Advising.\n","Emotional flooding: Persuasion, Empowerment, Advising.\n","Cognitive attribition: Cognitive change inducement, Persuasion, Empowerment.\n","Level of risk: Persuasion, Offering group support, Advising.\n","\n","Also, referring the customer to get further help may be useful in extreme cases.\n","For this task, all referrals must go to UK helplines:\n","\n","For urgent risk cases - Emergency Services: 999.\n","For high risk cases - Samaritans: 116 123.\n","For high risk cases where the patient might not want to call - Text SHOUT: 85258.\n","**\n","\n","Input summary to be used for response: {summary}\\n\n","\n","<|assistant|> Response:\\n\n","\n","\"\"\""],"metadata":{"id":"jOOgCDIqZ_dh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating responses for chosen model"],"metadata":{"id":"v76-Bc5uWW4S"}},{"cell_type":"code","source":["def extract_assistant_response(text):\n","    assistant_marker = \"Response:\"\n","    if assistant_marker in text:\n","        summary = text.split(assistant_marker)[1].strip()\n","    else:\n","        summary = text.strip()\n","    response = summary.split('\\n\\n\\n')[0].strip()\n","\n","    return response\n","\n","results = []\n","\n","for user_id in summary_df['userid'].unique():\n","  risk_rating = risk_supportiveness_df[risk_supportiveness_df['userid'] == user_id]['risk_rating'].iloc[0]\n","  #if risk_rating > 2:\n","    print(user_id)\n","    summary = summary_df[summary_df['userid'] == user_id]['summary'].values[0]\n","    full_summary = create_summary(summary,user_id,risk_supportiveness_df)\n","    input_text_zero = Zero_prompt_model1.format(summary=full_summary)\n","    cot_text_zero = CoT_prompt_model1.format(summary=full_summary)\n","    input_zero = tokenizer1(input_text_zero, return_tensors=\"pt\").to(\"cuda\")\n","    cot_zero = tokenizer1(cot_text_zero, return_tensors=\"pt\").to(\"cuda\")\n","    outputs_zero = model1.generate(**input_zero, max_new_tokens=500)\n","    outputs_cot = model1.generate(**cot_zero, max_new_tokens=500)\n","\n","    response_zero = extract_assistant_response(tokenizer1.decode(outputs_zero[0], skip_special_tokens=True))\n","    response_cot = extract_assistant_response(tokenizer1.decode(outputs_cot[0], skip_special_tokens=True))\n","\n","    results.append({\n","        'user_id': user_id,\n","        'summary': full_summary,\n","        'response_zero': response_zero,\n","        'response_cot': response_cot\n","    })"],"metadata":{"id":"4plU4tY36tNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(results)"],"metadata":{"id":"7fxVx8PHyihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install textstat"],"metadata":{"id":"drPdmnhUxxYd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialising and running response tests for Tulu Model\n"],"metadata":{"id":"K4yYy3MzWfFl"}},{"cell_type":"code","source":["import textstat\n","from concurrent.futures import ThreadPoolExecutor\n","sentiment_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","sentiment_pipeline = pipeline(\"sentiment-analysis\", model=sentiment_model_name)\n","empathy_model_name = \"bdotloh/roberta-base-empathy\"\n","empathy_tokenizer = AutoTokenizer.from_pretrained(empathy_model_name)\n","empathy_model = AutoModelForSequenceClassification.from_pretrained(empathy_model_name)\n","empathy_pipeline = pipeline(\"text-classification\", model=empathy_model, tokenizer=empathy_tokenizer)\n","\n","def flesch(response):\n","    return textstat.flesch_reading_ease(response), textstat.flesch_kincaid_grade(response)\n","\n","def bert_score(summary, response):\n","    P, R, F1 = score([response], [summary], lang=\"en\", verbose=False)\n","    return P.mean().item(), R.mean().item(), F1.mean().item()\n","\n","def sentiment_analysis_batch(responses):\n","    return [result['score'] for result in sentiment_pipeline(responses, batch_size=len(responses))]\n","\n","def empathy_detection_batch(responses):\n","    return [result['score'] for result in empathy_pipeline(responses, batch_size=len(responses))]\n"],"metadata":{"id":"IZ_jA-_bxnDq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flesch_readability_zero, flesch_grade_zero = [], []\n","flesch_readability_cot, flesch_grade_cot = [], []\n","bert_precision_zero, bert_precision_cot = [], []\n","bert_recall_zero, bert_recall_cot = [], []\n","sentiment_zero, sentiment_cot = [], []\n","empathy_zero, empathy_cot = [], []\n","responses_zero = [result['response_zero'] for result in results]\n","responses_cot = [result['response_cot'] for result in results]\n","summaries = [result['summary'] for result in results]\n","\n","with ThreadPoolExecutor() as executor:\n","    flesch_results_zero = list(executor.map(flesch, responses_zero))\n","    flesch_results_cot = list(executor.map(flesch, responses_cot))\n","\n","flesch_readability_zero, flesch_grade_zero = zip(*flesch_results_zero)\n","flesch_readability_cot, flesch_grade_cot = zip(*flesch_results_cot)\n","\n","with ThreadPoolExecutor() as executor:\n","    bert_scores_zero = list(executor.map(bert_score, summaries, responses_zero))\n","    bert_scores_cot = list(executor.map(bert_score, summaries, responses_cot))\n","\n","bert_precision_zero, bert_recall_zero = zip(*[(bp[0], bp[1]) for bp in bert_scores_zero])\n","bert_precision_cot, bert_recall_cot = zip(*[(bp[0], bp[1]) for bp in bert_scores_cot])\n","\n","sentiment_zero = sentiment_analysis_batch(responses_zero)\n","sentiment_cot = sentiment_analysis_batch(responses_cot)\n","empathy_zero = empathy_detection_batch(responses_zero)\n","empathy_cot = empathy_detection_batch(responses_cot)\n","\n","for i, result in enumerate(results):\n","    result['flesch_readability_zero'] = flesch_readability_zero[i]\n","    result['flesch_grade_zero'] = flesch_grade_zero[i]\n","    result['flesch_readability_cot'] = flesch_readability_cot[i]\n","    result['flesch_grade_cot'] = flesch_grade_cot[i]\n","    result['bert_precision_zero'] = bert_precision_zero[i]\n","    result['bert_precision_cot'] = bert_precision_cot[i]\n","    result['bert_recall_zero'] = bert_recall_zero[i]\n","    result['bert_recall_cot'] = bert_recall_cot[i]\n","    result['sentiment_zero'] = sentiment_zero[i]\n","    result['sentiment_cot'] = sentiment_cot[i]\n","    result['empathy_zero'] = empathy_zero[i]\n","    result['empathy_cot'] = empathy_cot[i]\n"],"metadata":{"id":"tYqJuwAf_55K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Zero Prompt Scores:\")\n","print(\"Flesch Readability Score:\", sum(flesch_readability_zero)/len(flesch_readability_zero))\n","print(\"Flesch Grade Level Score:\", sum(flesch_grade_zero)/len(flesch_grade_zero))\n","print(\"BERT Precision Score:\", sum(bert_precision_zero)/len(bert_precision_zero))\n","print(\"BERT Recall Score:\", sum(bert_recall_zero)/len(bert_recall_zero))\n","print(\"Sentiment Score:\", sum(sentiment_zero)/len(sentiment_zero))\n","print(\"Empathy Score:\", sum(empathy_zero)/len(empathy_zero))\n","\n","print(\"\\nCoT Prompt Scores:\")\n","print(\"Flesch Readability Score:\", sum(flesch_readability_cot)/len(flesch_readability_cot))\n","print(\"Flesch Grade Level Score:\", sum(flesch_grade_cot)/len(flesch_grade_cot))\n","print(\"BERT Precision Score:\", sum(bert_precision_cot)/len(bert_precision_cot))\n","print(\"BERT Recall Score:\", sum(bert_recall_cot)/len(bert_recall_cot))\n","print(\"Sentiment Score:\", sum(sentiment_cot)/len(sentiment_cot))\n","print(\"Empathy Score:\", sum(empathy_cot)/len(empathy_cot))\n","\n","results_df = pd.DataFrame(results)\n","results_df.to_csv('/content/drive/My Drive/Diss_Dataset/results_chatbot3.csv', index=False)"],"metadata":{"id":"7XyXlzhRHx2X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prompts for Mistral-7b-instruct-v0.3 model"],"metadata":{"id":"cDMwl4_iWyYd"}},{"cell_type":"code","source":["Zero_prompt_model1 = \"\"\"\n","[INST]\n","In one paragraph, produce a response to the patient (referred to as the author), based on the provided summary.\\n\n","Assume the patient is based in the UK with the following helplines:\\n\n","Emergency Services: 999.\n","Samaritans helpline: 116 123.\n","SHOUT texting helpline: 85258.\n","\n","#Input summary to be used for response: {summary}\\n\n","\n","Response:[/INST]\n","\n","\"\"\""],"metadata":{"id":"-QgzU6agLnh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CoT_prompt_model1 = \"\"\"\n","[INST]\n","As a mental health expert, your task is to provide a positive, empathetic and supportative message to the patient (referred to as the author), directly from the provided summary.\n","\n","#Consider:\n","**\n","Consider these suggested response stragegies by potiential characteristics of the message, only include the response strategies most related to the patients's needs:\n","Loss of control:  Advising, Interpretation, Offering Group Support, Emotional Support.\n","Acute loneliness: Offering Group Support, Cogitive Change Inducement, Interpretation.\n","Emptiness: Persuasion, Interpretation, Cognitive Change Inducement, Advising.\n","Narcissistic wound: Empowerment, Interpretation, Persuasion, Emotional Support.\n","Irreversibility: Emotional Support, Advising, Persuasion, Offering Group Support.\n","Loss of energy: Empowerment, Emotional Support, Advising.\n","Emotional flooding: Persuasion, Empowerment, Advising.\n","Cognitive attribition: Cognitive change inducement, Persuasion, Empowerment.\n","Level of risk: Persuasion, Offering group support, Advising.\n","\n","Also, referring the customer to get further help may be useful in extreme cases.\n","For this task, all referrals must go to UK helplines:\n","\n","For urgent risk cases - Emergency Services: 999.\n","For high risk cases - Samaritans: 116 123.\n","For high risk cases where the patient might not want to call - Text SHOUT: 85258.\n","**\n","\n","#Input summary to be used for response:\n","{summary}\\n\n","#Response: [/INST]\n","\n","\"\"\""],"metadata":{"id":"lzaaW9_BL5xE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialising and running response tests for Mistral model"],"metadata":{"id":"RA5AjE1bW4Ei"}},{"cell_type":"code","source":["flesch_readability_zero, flesch_grade_zero = [], []\n","flesch_readability_cot, flesch_grade_cot = [], []\n","bert_precision_zero, bert_precision_cot = [], []\n","bert_recall_zero, bert_recall_cot = [], []\n","sentiment_zero, sentiment_cot = [], []\n","empathy_zero, empathy_cot = [], []\n","responses_zero = [result['response_zero'] for result in results]\n","responses_cot = [result['response_cot'] for result in results]\n","summaries = [result['summary'] for result in results]\n","\n","with ThreadPoolExecutor() as executor:\n","    flesch_results_zero = list(executor.map(flesch, responses_zero))\n","    flesch_results_cot = list(executor.map(flesch, responses_cot))\n","\n","flesch_readability_zero, flesch_grade_zero = zip(*flesch_results_zero)\n","flesch_readability_cot, flesch_grade_cot = zip(*flesch_results_cot)\n","\n","with ThreadPoolExecutor() as executor:\n","    bert_scores_zero = list(executor.map(bert_score, summaries, responses_zero))\n","    bert_scores_cot = list(executor.map(bert_score, summaries, responses_cot))\n","\n","bert_precision_zero, bert_recall_zero = zip(*[(bp[0], bp[1]) for bp in bert_scores_zero])\n","bert_precision_cot, bert_recall_cot = zip(*[(bp[0], bp[1]) for bp in bert_scores_cot])\n","\n","sentiment_zero = sentiment_analysis_batch(responses_zero)\n","sentiment_cot = sentiment_analysis_batch(responses_cot)\n","empathy_zero = empathy_detection_batch(responses_zero)\n","empathy_cot = empathy_detection_batch(responses_cot)\n","\n","for i, result in enumerate(results):\n","    result['flesch_readability_zero'] = flesch_readability_zero[i]\n","    result['flesch_grade_zero'] = flesch_grade_zero[i]\n","    result['flesch_readability_cot'] = flesch_readability_cot[i]\n","    result['flesch_grade_cot'] = flesch_grade_cot[i]\n","    result['bert_precision_zero'] = bert_precision_zero[i]\n","    result['bert_precision_cot'] = bert_precision_cot[i]\n","    result['bert_recall_zero'] = bert_recall_zero[i]\n","    result['bert_recall_cot'] = bert_recall_cot[i]\n","    result['sentiment_zero'] = sentiment_zero[i]\n","    result['sentiment_cot'] = sentiment_cot[i]\n","    result['empathy_zero'] = empathy_zero[i]\n","    result['empathy_cot'] = empathy_cot[i]\n"],"metadata":{"id":"ftbJVIojNJKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Zero Prompt Scores:\")\n","print(\"Flesch Readability Score:\", sum(flesch_readability_zero)/len(flesch_readability_zero))\n","print(\"Flesch Grade Level Score:\", sum(flesch_grade_zero)/len(flesch_grade_zero))\n","print(\"BERT Precision Score:\", sum(bert_precision_zero)/len(bert_precision_zero))\n","print(\"BERT Recall Score:\", sum(bert_recall_zero)/len(bert_recall_zero))\n","print(\"Sentiment Score:\", sum(sentiment_zero)/len(sentiment_zero))\n","print(\"Empathy Score:\", sum(empathy_zero)/len(empathy_zero))\n","\n","print(\"\\nCoT Prompt Scores:\")\n","print(\"Flesch Readability Score:\", sum(flesch_readability_cot)/len(flesch_readability_cot))\n","print(\"Flesch Grade Level Score:\", sum(flesch_grade_cot)/len(flesch_grade_cot))\n","print(\"BERT Precision Score:\", sum(bert_precision_cot)/len(bert_precision_cot))\n","print(\"BERT Recall Score:\", sum(bert_recall_cot)/len(bert_recall_cot))\n","print(\"Sentiment Score:\", sum(sentiment_cot)/len(sentiment_cot))\n","print(\"Empathy Score:\", sum(empathy_cot)/len(empathy_cot))\n","\n","results_df = pd.DataFrame(results)\n","results_df.to_csv('/content/drive/My Drive/Diss_Dataset/results_chatbot2.csv', index=False)"],"metadata":{"id":"ks82JCVuNH19"},"execution_count":null,"outputs":[]}]}