{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMmAtumaJkGWDUJ1H0Z00+2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import required libraries"],"metadata":{"id":"utoRKai432x5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKUO0-WXtetQ"},"outputs":[],"source":["!pip install transformers torch accelerate tensorflow-hub bert-tensorflow tensorflow tqdm"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification, MarianMTModel, MarianTokenizer, BertConfig\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, TFBertForSequenceClassification\n","from transformers import LlamaTokenizer, LlamaForCausalLM\n","from sklearn.utils.class_weight import compute_class_weight\n","from torch.utils.data import Dataset\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import resample\n","import pandas as pd\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from datetime import datetime\n","from torch.utils.data import DataLoader\n","import re\n","import nltk\n","from nltk.corpus import wordnet\n","import random\n","from tqdm import tqdm\n","import concurrent.futures\n","from nltk.tokenize import sent_tokenize\n","import matplotlib.pyplot as plt\n","import json\n","import numpy as np\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"id":"tFcCUC3QthR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"C-YChUoOvr3K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Re-read all sentences with labels"],"metadata":{"id":"au7wFaPC38GU"}},{"cell_type":"code","source":["csv_filenmame = \"/content/drive/My Drive/Diss_Dataset/all_labels_combined.csv\"\n","sentences2_df = pd.read_csv(csv_filenmame)"],"metadata":{"id":"IXV_b34Zti4o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import RoBERTa sentiment classifier"],"metadata":{"id":"tFcw_Da04CiB"}},{"cell_type":"code","source":["model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n","sentiment_analysis = pipeline('sentiment-analysis', model=model_name, device=0)\n","unique_user_ids = sentences2_df['userid'].unique()\n","all_top_sentences = []"],"metadata":{"id":"8VOhEKrVtmpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Produce list of 5 most suicidal/negative sentences for each user"],"metadata":{"id":"HwsHzykK4LGn"}},{"cell_type":"code","source":["for user_id in unique_user_ids:\n","    user_sentences = sentences2_df[(sentences2_df['userid'] == user_id) &\n","                                   (sentences2_df['predicted_supportiveness_label'] == 0) &\n","                                   (sentences2_df['rating'] > 1)]\n","\n","    category_counts = user_sentences['rating'].value_counts().sort_index(ascending=False)\n","    total_sentences = 0\n","    selected_categories = []\n","\n","    for rating, count in category_counts.items():\n","        total_sentences += count\n","        selected_categories.append(rating)\n","        if total_sentences > 5:\n","            break\n","    if not selected_categories:\n","        print(f\"No sentences found for user {user_id} after filtering. Skipping this user.\")\n","        continue\n","    lowest_category = min(selected_categories)\n","    lowest_category_sentences = user_sentences[user_sentences['rating'] == lowest_category]\n","    lowest_category_sentences['negative_score'] = lowest_category_sentences['sentence'].apply(\n","        lambda x: sentiment_analysis(x)[0]['score'] if sentiment_analysis(x)[0]['label'].lower() == 'negative' else 0\n","    )\n","\n","    lowest_category_sentences = lowest_category_sentences.sort_values(by='negative_score', ascending=False)\n","    top_sentences = user_sentences[user_sentences['rating'].isin(selected_categories[:-1])]\n","    top_sentences = pd.concat([top_sentences, lowest_category_sentences.head(5 - len(top_sentences))])\n","    top_sentences = top_sentences.head(5)\n","    all_top_sentences.append(top_sentences)"],"metadata":{"id":"PrsLVxuQuDso"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save results to a CSV file"],"metadata":{"id":"oOgv9qQC4UFR"}},{"cell_type":"code","source":["final_top_sentences = pd.concat(all_top_sentences)\n","final_top_sentences.to_csv('/content/drive/My Drive/Diss_Dataset/top_sentences_for_all_users.csv', index=False)\n","\n","print(final_top_sentences)"],"metadata":{"id":"VcQdo8iQu8nv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function to generate a risk rating for each user"],"metadata":{"id":"SmUwS_bm4ZG5"}},{"cell_type":"code","source":["def calculate_user_risk_rating(user_sentences, supportiveness_ratio):\n","    if user_sentences.empty:\n","        return 0\n","\n","    rating_counts = user_sentences['rating'].value_counts()\n","    max_rating = user_sentences['rating'].max()\n","    print(user_sentences)\n","    if supportiveness_ratio >= 0.9:\n","        if max_rating < 4:\n","            return 1\n","\n","    ratings_of_4_or_5 = user_sentences[user_sentences['rating'].isin([4, 5])]\n","    print(ratings_of_4_or_5)\n","    all_other_ratings_are_2 = user_sentences[user_sentences['rating'] != 2].shape[0] == len(ratings_of_4_or_5)\n","    if supportiveness_ratio >= 0.87 and len(ratings_of_4_or_5) == 1 and all_other_ratings_are_2:\n","        return 1\n","    if supportiveness_ratio >= 0.87 and len(user_sentences) in {1,2}:\n","        return 1\n","\n","    if 4 in user_sentences['rating'].values or 5 in user_sentences['rating'].values:\n","        print(\"hi\")\n","        if len(ratings_of_4_or_5) >= 1:\n","            print(\"hi2\")\n","            if user_sentences['rating'].mean() > 4.5:\n","                return 5\n","            if user_sentences['rating'].mean() > 3.5:\n","                return 4\n","            else:\n","                return max(3, int(user_sentences['rating'].mean()))\n","\n","    num_rated_3 = (user_sentences['rating'] == 3).sum()\n","    num_sentences = len(user_sentences)\n","    if num_rated_3 > (num_sentences * 0.3):\n","        return 3\n","    return int(user_sentences['rating'].mean())"],"metadata":{"id":"36poritPHkhT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Saving user risk levels to CSV file"],"metadata":{"id":"OLpgdwm54d3D"}},{"cell_type":"code","source":["user_risk_ratings = {}\n","user_supportiveness_ratios = {}\n","\n","for user_id in sentences2_df['userid'].unique():\n","    user_sentences = final_top_sentences[final_top_sentences['userid'] == user_id]\n","    supportive_sentences = sentences2_df[(sentences2_df['userid'] == user_id) & (sentences2_df['predicted_supportiveness_label'] == 1)]\n","    all_sentences = sentences2_df[sentences2_df['userid'] == user_id]\n","\n","    supportive_ratio = len(supportive_sentences) / len(all_sentences) if len(all_sentences) > 0 else 0\n","    user_risk_ratings[user_id] = calculate_user_risk_rating(user_sentences, supportive_ratio)\n","    user_supportiveness_ratios[user_id] = supportive_ratio\n","user_risk_df = pd.DataFrame({\n","    'userid': list(user_risk_ratings.keys()),\n","    'risk_rating': list(user_risk_ratings.values()),\n","    'supportiveness_ratio': list(user_supportiveness_ratios.values())\n","})\n","\n","user_risk_df.to_csv('/content/drive/My Drive/Diss_Dataset/user_risk_with_supportiveness.csv', index=False)\n","\n","final_top_sentences_sorted = final_top_sentences.sort_values(by=['userid', 'rating'], ascending=[True, False])\n","final_top_sentences.to_csv('/content/drive/My Drive/Diss_Dataset/top_5_sentences_per_user.csv', index=False)\n","\n","\n","print(user_risk_df)"],"metadata":{"id":"rbzg4YUtUWkr"},"execution_count":null,"outputs":[]}]}